{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b337c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "from cleantext import clean\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['https_www','seems_like','do','not','imgur','tkg','https','http','could','www','com','ever','doesnt_seem',\n",
    "                  'xxxx','else','would','also','ea','&amp','#x200B','oh','etc','yeah','nan','however','even','dont_know','sa',\n",
    "                  \"looks_like\",'especially','may','sounds_like'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84396c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3021, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5447ao</td>\n",
       "      <td>What is Google Assistant and how does it work?</td>\n",
       "      <td>Recently, Google launched a product Google Ass...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>TricksNDeals</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-23 19:18:25</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/5447ao/what_is_goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>What is Google Assistant and how does it work?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                           title  \\\n",
       "0  5447ao  What is Google Assistant and how does it work?   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Recently, Google launched a product Google Ass...   \n",
       "\n",
       "                                           full_link        author  score  \\\n",
       "0  https://www.reddit.com/r/googleassistant/comme...  TricksNDeals      2   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-09-23 19:18:25                0   \n",
       "\n",
       "                                           permalink flair comment_msg  \\\n",
       "0  /r/googleassistant/comments/5447ao/what_is_goo...   NaN     ['nan']   \n",
       "\n",
       "                                             content  \n",
       "0  What is Google Assistant and how does it work?...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoadDataset\n",
    "df=pd.read_csv('googleassistant_merged.csv')\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb11e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5447ao</td>\n",
       "      <td>What is Google Assistant and how does it work?</td>\n",
       "      <td>Recently, Google launched a product Google Ass...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>TricksNDeals</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-23 19:18:25</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/5447ao/what_is_goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>what is google assistant and how does it work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5448oa</td>\n",
       "      <td>What is Google Assistant, how does it work and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>TricksNDeals</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-23 19:30:43</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/5448oa/what_is_goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>what is google assistant how does it work and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>54larn</td>\n",
       "      <td>Allo Easter Egg (All your base)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-27 00:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/54larn/allo_easter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>allo easter egg all your base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>55vthv</td>\n",
       "      <td>Google Assistant in Nexus</td>\n",
       "      <td>Will google assistant(Like the one showed toda...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>pra_van</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-05 05:06:52</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/googleassistant/comments/55vthv/google_assi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['It will not, not in 7.1']</td>\n",
       "      <td>google assistant in nexus will google assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>55wfv5</td>\n",
       "      <td>Offical Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>YePitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-05 07:14:59</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/55wfv5/offical_site/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>offical site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3016</td>\n",
       "      <td>no1u1w</td>\n",
       "      <td>What? I just really don't know what to say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>Debris_Ninja_Fighter</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-30 10:41:11</td>\n",
       "      <td>8</td>\n",
       "      <td>/r/googleassistant/comments/no1u1w/what_i_just...</td>\n",
       "      <td>Bug</td>\n",
       "      <td>['https://i.imgur.com/1veAlMl.jpg This is just...</td>\n",
       "      <td>what i just really dont know what to say this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3017</td>\n",
       "      <td>no9xnj</td>\n",
       "      <td>Is there any way to stop Assistant from tellin...</td>\n",
       "      <td>Getting a bit narked off with Assistant now th...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>ErTnEc</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-30 20:13:24</td>\n",
       "      <td>5</td>\n",
       "      <td>/r/googleassistant/comments/no9xnj/is_there_an...</td>\n",
       "      <td>Tech Support</td>\n",
       "      <td>[\"Are you on iOS? Because I'm betting Apple Mu...</td>\n",
       "      <td>is there any way to stop assistant from tellin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3018</td>\n",
       "      <td>nodi7h</td>\n",
       "      <td>Can I use Google Assistant to play music using...</td>\n",
       "      <td>Hola people,\\n\\nWhenever I'm cycling, I don't ...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>An-Onymous-Name</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-30 23:27:17</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/googleassistant/comments/nodi7h/can_i_use_g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['I had no success with Audify but Pulsar work...</td>\n",
       "      <td>can i use google assistant to play music using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3019</td>\n",
       "      <td>noogbk</td>\n",
       "      <td>Does Google assistant have its own data Or if ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>Sleepingtide</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 08:34:33</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/noogbk/does_google...</td>\n",
       "      <td>Question</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>does google assistant have its own data or if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>nozyap</td>\n",
       "      <td>Is there a way to speed up sending a message?</td>\n",
       "      <td>It's a slow process using Google assistant to ...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>Ritz5</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 18:09:43</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/googleassistant/comments/nozyap/is_there_a_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"I haven't found a way but I agree.... Annoyi...</td>\n",
       "      <td>is there a way to speed up sending a message i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3021 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                              title  \\\n",
       "0     5447ao     What is Google Assistant and how does it work?   \n",
       "1     5448oa  What is Google Assistant, how does it work and...   \n",
       "2     54larn                    Allo Easter Egg (All your base)   \n",
       "3     55vthv                          Google Assistant in Nexus   \n",
       "4     55wfv5                                       Offical Site   \n",
       "...      ...                                                ...   \n",
       "3016  no1u1w         What? I just really don't know what to say   \n",
       "3017  no9xnj  Is there any way to stop Assistant from tellin...   \n",
       "3018  nodi7h  Can I use Google Assistant to play music using...   \n",
       "3019  noogbk  Does Google assistant have its own data Or if ...   \n",
       "3020  nozyap      Is there a way to speed up sending a message?   \n",
       "\n",
       "                                               selftext  \\\n",
       "0     Recently, Google launched a product Google Ass...   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     Will google assistant(Like the one showed toda...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "3016                                                NaN   \n",
       "3017  Getting a bit narked off with Assistant now th...   \n",
       "3018  Hola people,\\n\\nWhenever I'm cycling, I don't ...   \n",
       "3019                                                NaN   \n",
       "3020  It's a slow process using Google assistant to ...   \n",
       "\n",
       "                                              full_link                author  \\\n",
       "0     https://www.reddit.com/r/googleassistant/comme...          TricksNDeals   \n",
       "1     https://www.reddit.com/r/googleassistant/comme...          TricksNDeals   \n",
       "2     https://www.reddit.com/r/googleassistant/comme...             [deleted]   \n",
       "3     https://www.reddit.com/r/googleassistant/comme...               pra_van   \n",
       "4     https://www.reddit.com/r/googleassistant/comme...               YePitch   \n",
       "...                                                 ...                   ...   \n",
       "3016  https://www.reddit.com/r/googleassistant/comme...  Debris_Ninja_Fighter   \n",
       "3017  https://www.reddit.com/r/googleassistant/comme...                ErTnEc   \n",
       "3018  https://www.reddit.com/r/googleassistant/comme...       An-Onymous-Name   \n",
       "3019  https://www.reddit.com/r/googleassistant/comme...          Sleepingtide   \n",
       "3020  https://www.reddit.com/r/googleassistant/comme...                 Ritz5   \n",
       "\n",
       "      score         publish_date  num_of_comments  \\\n",
       "0         2  2016-09-23 19:18:25                0   \n",
       "1         2  2016-09-23 19:30:43                0   \n",
       "2         1  2016-09-27 00:00:31                0   \n",
       "3         2  2016-10-05 05:06:52                1   \n",
       "4         1  2016-10-05 07:14:59                0   \n",
       "...     ...                  ...              ...   \n",
       "3016      1  2021-05-30 10:41:11                8   \n",
       "3017      1  2021-05-30 20:13:24                5   \n",
       "3018      1  2021-05-30 23:27:17                1   \n",
       "3019      1  2021-05-31 08:34:33                0   \n",
       "3020      1  2021-05-31 18:09:43                1   \n",
       "\n",
       "                                              permalink         flair  \\\n",
       "0     /r/googleassistant/comments/5447ao/what_is_goo...           NaN   \n",
       "1     /r/googleassistant/comments/5448oa/what_is_goo...           NaN   \n",
       "2     /r/googleassistant/comments/54larn/allo_easter...           NaN   \n",
       "3     /r/googleassistant/comments/55vthv/google_assi...           NaN   \n",
       "4      /r/googleassistant/comments/55wfv5/offical_site/           NaN   \n",
       "...                                                 ...           ...   \n",
       "3016  /r/googleassistant/comments/no1u1w/what_i_just...           Bug   \n",
       "3017  /r/googleassistant/comments/no9xnj/is_there_an...  Tech Support   \n",
       "3018  /r/googleassistant/comments/nodi7h/can_i_use_g...           NaN   \n",
       "3019  /r/googleassistant/comments/noogbk/does_google...      Question   \n",
       "3020  /r/googleassistant/comments/nozyap/is_there_a_...           NaN   \n",
       "\n",
       "                                            comment_msg  \\\n",
       "0                                               ['nan']   \n",
       "1                                               ['nan']   \n",
       "2                                               ['nan']   \n",
       "3                           ['It will not, not in 7.1']   \n",
       "4                                               ['nan']   \n",
       "...                                                 ...   \n",
       "3016  ['https://i.imgur.com/1veAlMl.jpg This is just...   \n",
       "3017  [\"Are you on iOS? Because I'm betting Apple Mu...   \n",
       "3018  ['I had no success with Audify but Pulsar work...   \n",
       "3019                                            ['nan']   \n",
       "3020  [\"I haven't found a way but I agree.... Annoyi...   \n",
       "\n",
       "                                                content  \n",
       "0     what is google assistant and how does it work ...  \n",
       "1     what is google assistant how does it work and ...  \n",
       "2                        allo easter egg all your base   \n",
       "3     google assistant in nexus will google assistan...  \n",
       "4                                         offical site   \n",
       "...                                                 ...  \n",
       "3016  what i just really dont know what to say this ...  \n",
       "3017  is there any way to stop assistant from tellin...  \n",
       "3018  can i use google assistant to play music using...  \n",
       "3019  does google assistant have its own data or if ...  \n",
       "3020  is there a way to speed up sending a message i...  \n",
       "\n",
       "[3021 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI)\n",
    "\n",
    "def preprocess_tweet(row):\n",
    "    text = row['content']\n",
    "    text = text.replace('r/','')\n",
    "    text = p.clean(text)\n",
    "    text = clean(text,     \n",
    "                 fix_unicode=True,              # fix various unicode errors\n",
    "                 to_ascii=True,                 # transliterate to closest ASCII representation\n",
    "                 lower=True,                    # lowercase text\n",
    "                 no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                 no_urls=True,                  # replace all URLs with a special token\n",
    "                 no_emails=True,                # replace all email addresses with a special token\n",
    "                 no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                 no_numbers=True,               # replace all numbers with a special token\n",
    "                 no_digits=True,                # replace all digits with a special token\n",
    "                 no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                 no_punct=True,                 # remove punctuations\n",
    "                 lang=\"en\",                     # set to 'de' for German special handling\n",
    "                 replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                 replace_with_url=\"\",\n",
    "                 replace_with_email=\"\",\n",
    "                 replace_with_phone_number=\"\",\n",
    "                 replace_with_number=\"\",\n",
    "                 replace_with_digit=\"\",\n",
    "                 replace_with_currency_symbol=\"\"\n",
    "                )\n",
    "    text = text.replace('amp','')\n",
    "    text = text.replace('nan','')\n",
    "    return text\n",
    "\n",
    "df['content'] = df.apply(preprocess_tweet, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11fcc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'google', 'assistant', 'and', 'how', 'does', 'it', 'work', 'recently', 'google', 'launched', 'product', 'google', 'assistant', 'that', 'has', 'the', 'caliber', 'of', 'taking', 'over', 'the', 'tech', 'market', 'google', 'has', 'planned', 'to', 'go', 'face', 'to', 'face', 'with', 'apples', 'siri', 'and', 'amazons', 'alexa', 'due', 'to', 'the', 'fear', 'of', 'losing', 'the', 'market', 'of', 'artificial', 'intelligenceai', 'google', 'has', 'come', 'up', 'with', 'an', 'innovative', 'and', 'user', 'friendly', 'product', 'known', 'as', 'google', 'assistant', 'it', 'can', 'be', 'taken', 'as', 'an', 'upgraded', 'version', 'of', 'google', 'now', 'google', 'now', 'can', 'do', 'many', 'things', 'for', 'you', 'like', 'searching', 'and', 'the', 'most', 'important', 'feature', 'being', 'the', 'google', 'now', 'cards', 'that', 'shows', 'you', 'useful', 'information', 'about', 'almost', 'everything', 'you', 'need', 'in', 'the', 'annual', 'google', 'io', 'developer', 'conference', 'back', 'in', 'may', 'google', 'talked', 'about', 'google', 'assistant', 'the', 'main', 'motive', 'of', 'this', 'new', 'virtual', 'assistant', 'was', 'seen', 'as', 'an', 'improvement', 'in', 'the', 'google', 'nows', 'two', 'way', 'conversation', 'experience', 'if', 'you', 'have', 'any', 'doubts', 'about', 'any', 'of', 'the', 'things', 'we', 'have', 'talked', 'about', 'till', 'now', 'dont', 'worry', 'we', 'have', 'discussed', 'everything', 'in', 'very', 'detail', 'below', 'what', 'is', 'google', 'assistant', 'google', 'assistant', 'is', 'new', 'virtual', 'assistant', 'that', 'google', 'sees', 'as', 'an', 'improvised', 'version', 'of', 'its', 'current', 'google', 'now', 'assistant', 'it', 'can', 'be', 'seen', 'as', 'and', 'upgraded', 'or', 'extended', 'version', 'of', 'the', 'google', 'now', 'the', 'very', 'first', 'assistant', 'that', 'got', 'popular', 'in', 'the', 'market', 'was', 'apples', 'siri', 'since', 'then', 'google', 'had', 'been', 'working', 'upon', 'such', 'projects', 'the', 'ceo', 'of', 'google', 'sundar', 'pichai', 'said', 'we', 'at', 'google', 'want', 'people', 'to', 'experience', 'twoway', 'conversation', 'with', 'the', 'virtual', 'assistant', 'keeping', 'this', 'in', 'mind', 'google', 'followed', 'the', 'path', 'of', 'apples', 'siri', 'what', 'does', 'siri', 'do', 'siri', 'can', 'just', 'be', 'understood', 'like', 'your', 'assistant', 'that', 'can', 'do', 'almost', 'everything', 'you', 'want', 'from', 'weather', 'reports', 'to', 'setting', 'alarms', 'to', 'getting', 'the', 'live', 'scores', 'or', 'the', 'trending', 'news', 'siri', 'can', 'do', 'it', 'all', 'for', 'you', 'on', 'your', 'command', 'to', 'keep', 'up', 'with', 'the', 'siri', 'which', 'is', 'only', 'available', 'for', 'ios', 'google', 'introduced', 'google', 'now', 'for', 'android', 'the', 'fact', 'that', 'it', 'is', 'not', 'as', 'personal', 'and', 'handy', 'as', 'siri', 'but', 'it', 'has', 'feature', 'of', 'google', 'now', 'cards', 'which', 'can', 'fetch', 'the', 'lastest', 'information', 'that', 'you', 'need', 'from', 'google', 'the', 'most', 'significant', 'feature', 'was', 'scanning', 'your', 'mail', 'list', 'track', 'your', 'orders', 'important', 'dates', 'and', 'many', 'other', 'things', 'just', 'like', 'siri', 'for', 'ios', 'and', 'google', 'now', 'for', 'android', 'there', 'is', 'alexa', 'from', 'amazon', 'alexa', 'is', 'not', 'just', 'limited', 'to', 'ios', 'or', 'android', 'which', 'makes', 'it', 'special', 'it', 'can', 'be', 'found', 'in', 'companys', 'connected', 'bluetooth', 'speaker', 'known', 'as', 'amazon', 'echo', 'since', 'its', 'launch', 'in', 'the', 'year', 'amazon', 'echo', 'lets', 'you', 'do', 'unlimited', 'things', 'like', 'ordering', 'pizza', 'paying', 'the', 'bills', 'booking', 'the', 'uber', 'and', 'keeping', 'check', 'on', 'connected', 'devices', 'alexa', 'gained', 'so', 'much', 'popularity', 'in', 'small', 'time', 'that', 'it', 'needed', 'to', 'launch', 'two', 'different', 'versions', 'of', 'amazon', 'echo', 'inspired', 'by', 'this', 'google', 'too', 'launched', 'product', 'called', 'google', 'home', 'at', 'annual', 'google', 'io', 'developer', 'conference', 'it', 'is', 'quite', 'similar', 'to', 'amazon', 'echo', 'but', 'has', 'an', 'amazing', 'advantage', 'that', 'it', 'is', 'powered', 'by', 'google', 'assistant', 'in', 'the', 'conference', 'google', 'explained', 'the', 'assistant', 'as', 'the', 'assistant', 'is', 'conversational', 'an', 'ongoing', 'twoway', 'dialogue', 'between', 'you', 'and', 'google', 'that', 'understands', 'your', 'world', 'and', 'helps', 'you', 'get', 'things', 'done', 'it', 'makes', 'it', 'easy', 'to', 'buy', 'movie', 'tickets', 'while', 'on', 'the', 'go', 'to', 'find', 'that', 'perfect', 'restaurant', 'for', 'your', 'family', 'to', 'grab', 'quick', 'bite', 'before', 'the', 'movie', 'starts', 'and', 'then', 'help', 'you', 'navigate', 'to', 'the', 'theater', 'what', 'is', 'artificial', 'intelligence', 'artificial', 'intelligence', 'is', 'the', 'science', 'of', 'making', 'the', 'computers', 'to', 'the', 'work', 'that', 'if', 'done', 'by', 'humans', 'require', 'intelligence', 'and', 'thinking', 'ai', 'definitely', 'has', 'achieved', 'success', 'in', 'the', 'recent', 'past', 'but', 'it', 'is', 'limited', 'to', 'some', 'niches', 'and', 'domains', 'only', 'since', 'the', 'evolution', 'of', 'the', 'ai', 'years', 'back', 'not', 'much', 'of', 'advancement', 'has', 'come', 'to', 'ai', 'very', 'slow', 'growth', 'rate', 'of', 'ai', 'have', 'been', 'seen', 'as', 'achieving', 'humanlevel', 'intelligence', 'is', 'not', 'an', 'easy', 'task', 'at', 'all', 'benefits', 'of', 'artificial', 'intelligence', 'the', 'artificial', 'intelligence', 'is', 'very', 'accurate', 'and', 'precise', 'the', 'chances', 'of', 'error', 'are', 'almost', 'nil', 'intelligent', 'machines', 'can', 'replace', 'human', 'beings', 'in', 'many', 'areas', 'of', 'work', 'robots', 'with', 'the', 'help', 'of', 'ai', 'can', 'do', 'certain', 'difficult', 'tasks', 'which', 'have', 'long', 'been', 'carried', 'out', 'by', 'humans', 'it', 'is', 'possible', 'because', 'of', 'the', 'intelligence', 'programmed', 'the', 'machines', 'that', 'they', 'can', 'hold', 'greater', 'and', 'can', 'be', 'programmed', 'to', 'manage', 'themselves', 'many', 'organisations', 'use', 'digital', 'assistants', 'that', 'interact', 'with', 'the', 'user', 'for', 'increasing', 'and', 'enhancing', 'the', 'customer', 'support', 'when', 'we', 'play', 'computer', 'game', 'we', 'are', 'in', 'fact', 'interacting', 'with', 'artificial', 'intelligence', 'in', 'game', 'where', 'the', 'computer', 'plays', 'as', 'our', 'opponent', 'it', 'is', 'with', 'the', 'help', 'of', 'ai', 'that', 'the', 'machine', 'plans', 'the', 'game', 'moves', 'in', 'response', 'to', 'ours', 'thus', 'gaming', 'is', 'among', 'the', 'most', 'common', 'exles', 'of', 'the', 'advantages', 'of', 'artificial', 'intelligence', 'the', 'greatest', 'advantage', 'of', 'artificial', 'intelligence', 'is', 'that', 'machines', 'do', 'not', 'require', 'sleep', 'or', 'breaks', 'and', 'are', 'able', 'to', 'function', 'without', 'stopping', 'they', 'can', 'continuously', 'perform', 'the', 'same', 'task', 'without', 'getting', 'bored', 'or', 'tired', 'when', 'employed', 'to', 'carry', 'out', 'dangerous', 'tasks', 'the', 'risk', 'to', 'human', 'health', 'and', 'safety', 'is', 'reduced', 'how', 'does', 'google', 'assistant', 'work', 'the', 'google', 'assistant', 'is', 'an', 'artificial', 'intelligenceai', 'and', 'works', 'in', 'the', 'way', 'that', 'if', 'we', 'ask', 'question', 'it', 'again', 'throws', 'follow', 'up', 'questions', 'upon', 'us', 'when', 'we', 'answer', 'these', 'questions', 'it', 'keeps', 'record', 'of', 'the', 'whole', 'conversation', 'at', 'the', 'end', 'when', 'it', 'has', 'done', 'its', 'processing', 'determining', 'the', 'whole', 'situation', 'it', 'displays', 'the', 'best', 'answers', 'to', 'us', 'not', 'much', 'of', 'its', 'working', 'and', 'features', 'are', 'known', 'till', 'present', 'but', 'it', 'is', 'known', 'for', 'sure', 'that', 'it', 'is', 'coming', 'on', 'two', 'of', 'its', 'products', 'called', 'google', 'allo', 'and', 'google', 'home', 'google', 'allo', 'google', 'allo', 'allo', 'is', 'new', 'messaging', 'app', 'launched', 'by', 'google', 'for', 'ios', 'and', 'android', 'platform', 'calling', 'it', 'just', 'messaging', 'app', 'would', 'be', 'wrong', 'because', 'it', 'has', 'so', 'many', 'features', 'that', 'it', 'is', 'going', 'to', 'give', 'the', 'messaging', 'giants', 'tough', 'competition', 'it', 'was', 'introduced', 'in', 'google', 'io', 'conference', 'not', 'only', 'it', 'provides', 'you', 'with', 'the', 'messaging', 'feature', 'it', 'makes', 'your', 'chats', 'very', 'attractive', 'and', 'interactive', 'the', 'idea', 'is', 'same', 'as', 'whatsapp', 'ie', 'using', 'the', 'phone', 'number', 'for', 'starting', 'but', 'if', 'you', 'already', 'have', 'google', 'account', 'added', 'to', 'your', 'android', 'it', 'automatically', 'adds', 'it', 'to', 'your', 'profile', 'fllowing', 'the', 'footmarks', 'of', 'other', 'messengers', 'it', 'also', 'features', 'those', 'emojis', 'and', 'speakers', 'to', 'make', 'chats', 'fun', 'apart', 'from', 'all', 'of', 'these', 'google', 'assistant', 'still', 'remains', 'the', 'hottest', 'feature', 'as', 'we', 'have', 'seen', 'in', 'facebook', 'messenger', 'that', 'the', 'virtual', 'assistants', 'and', 'bots', 'are', 'used', 'google', 'also', 'did', 'the', 'same', 'thing', 'combining', 'these', 'assistants', 'and', 'bots', 'into', 'single', 'product', 'you', 'can', 'ask', 'questions', 'in', 'allo', 'by', 'simply', 'typing', 'google', 'followed', 'by', 'the', 'question', 'it', 'can', 'also', 'be', 'done', 'by', 'dictating', 'the', 'question', 'through', 'voice', 'mode', 'the', 'google', 'assistant', 'will', 'ask', 'more', 'follow', 'up', 'questions', 'and', 'once', 'fully', 'aware', 'of', 'the', 'context', 'it', 'responds', 'back', 'with', 'the', 'best', 'answers', 'lets', 'have', 'some', 'exle', 'to', 'learn', 'more', 'about', 'google', 'assistant', 'in', 'case', 'you', 'go', 'to', 'new', 'place', 'or', 'city', 'you', 'need', 'to', 'find', 'the', 'best', 'hotel', 'in', 'the', 'area', 'best', 'food', 'points', 'and', 'the', 'map', 'of', 'the', 'whole', 'city', 'in', 'that', 'case', 'google', 'assistant', 'will', 'help', 'you', 'with', 'all', 'its', 'potential', 'if', 'in', 'case', 'you', 'are', 'bored', 'and', 'too', 'tired', 'to', 'do', 'something', 'simply', 'ask', 'the', 'google', 'assistant', 'about', 'the', 'jokes', 'memes', 'and', 'funny', 'videos', 'it', 'will', 'search', 'the', 'best', 'available', 'on', 'the', 'google', 'just', 'like', 'facebook', 'messenger', 'it', 'also', 'features', 'in', 'chat', 'gaming', 'just', 'type', 'google', 'lets', 'play', 'game', 'and', 'you', 'will', 'get', 'the', 'option', 'to', 'play', 'emoji', 'games', 'allo', 'is', 'fulloffun', 'app', 'with', 'google', 'assistant', 'which', 'makes', 'the', 'experience', 'even', 'better', 'along', 'with', 'it', 'allo', 'even', 'has', 'an', 'incognito', 'mode', 'so', 'as', 'to', 'make', 'your', 'chats', 'private', 'the', 'chats', 'can', 'also', 'be', 'made', 'to', 'selfdestruct', 'after', 'specific', 'timeicoginito', 'feature', 'in', 'google', 'allo', 'google', 'home', 'google', 'home', 'google', 'home', 'just', 'like', 'amazon', 'echo', 'is', 'wifi', 'speaker', 'which', 'acts', 'as', 'an', 'assistant', 'for', 'the', 'whole', 'family', 'by', 'being', 'smarthome', 'control', 'centre', 'apart', 'from', 'being', 'just', 'an', 'entertainment', 'device', 'for', 'the', 'whole', 'house', 'it', 'also', 'helps', 'us', 'manage', 'everyday', 'tasks', 'and', 'ask', 'questions', 'to', 'google', 'all', 'of', 'this', 'is', 'possible', 'with', 'the', 'help', 'of', 'google', 'assistant', 'google', 'assistant', 'uses', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'to', 'determine', 'the', 'situations', 'of', 'the', 'questions', 'for', 'exle', 'if', 'we', 'type', 'lets', 'watch', 'the', 'legend', 'of', 'tarzan', 'it', 'will', 'show', 'the', 'results', 'of', 'the', 'ticket', 'booking', 'websites', 'if', 'we', 'ask', 'is', 'the', 'legend', 'of', 'tarzan', 'good', 'it', 'will', 'show', 'you', 'the', 'reviews', 'of', 'the', 'movie', 'trailer', 'and', 'the', 'ratings', 'by', 'the', 'various', 'websitesalso', 'it', 'has', 'the', 'capability', 'of', 'compiling', 'all', 'your', 'questions', 'together', 'and', 'showing', 'the', 'most', 'favorable', 'result', 'it', 'can', 'also', 'do', 'other', 'basic', 'things', 'like', 'maintaining', 'your', 'daily', 'schedule', 'commute', 'your', 'working', 'time', 'and', 'many', 'other', 'fascinating', 'things', 'all', 'with', 'the', 'help', 'of', 'google', 'assistant', 'integration', 'with', 'other', 'companies', 'google', 'home', 'can', 'give', 'you', 'the', 'functionality', 'to', 'be', 'the', 'control', 'center', 'of', 'your', 'home', 'using', 'the', 'google', 'assistant', 'it', 'will', 'give', 'us', 'various', 'benefits', 'like', 'setting', 'up', 'alarms', 'maintaining', 'todo', 'list', 'and', 'even', 'connecting', 'your', 'smarthome', 'and', 'leading', 'global', 'network', 'systems', 'it', 'means', 'you', 'might', 'be', 'able', 'to', 'control', 'your', 'fans', 'lights', 'doors', 'etc', 'in', 'the', 'near', 'future', 'google', 'is', 'even', 'planning', 'to', 'work', 'with', 'developers', 'for', 'even', 'more', 'ease', 'of', 'work', 'for', 'exle', 'booking', 'car', 'for', 'your', 'tour', 'sending', 'cards', 'and', 'flowers', 'to', 'your', 'beloved', 'ones', 'or', 'ordering', 'dinner', 'online', 'you', 'might', 'be', 'thinking', 'whats', 'the', 'benefit', 'in', 'that', 'when', 'we', 'are', 'still', 'doing', 'these', 'things', 'online', 'the', 'answer', 'is', 'all', 'of', 'these', 'will', 'be', 'done', 'with', 'just', 'the', 'help', 'of', 'your', 'voice', 'you', 'dont', 'need', 'to', 'click', 'excessively', 'or', 'pay', 'every', 'time', 'alexa', 'is', 'already', 'integrated', 'with', 'some', 'big', 'third', 'party', 'applications', 'and', 'softwares', 'like', 'spotify', 'iftt', 'uber', 'dominoes', 'phillips', 'belkin', 'and', 'many', 'more', 'seeing', 'this', 'now', 'apple', 'also', 'announced', 'that', 'it', 'will', 'also', 'be', 'releasing', 'siri', 'speaker', 'which', 'will', 'be', 'open', 'to', 'third', 'party', 'developers', 'and', 'the', 'google', 'assistant', 'is', 'also', 'working', 'on', 'third', 'party', 'integration', 'when', 'can', 'you', 'use', 'google', 'assistant', 'google', 'assistant', 'can', 'easily', 'be', 'accessed', 'and', 'enjoyed', 'through', 'the', 'google', 'allo', 'app', 'which', 'is', 'already', 'available', 'on', 'the', 'playstore', 'but', 'google', 'has', 'assured', 'that', 'it', 'will', 'available', 'throughout', 'the', 'google', 'ecosystem', 'by', 'october', 'along', 'with', 'some', 'other', 'major', 'product', 'launch', 'the', 'long', 'awaited', 'pixel', 'phones', 'and', 'google', 'home', 'router', 'will', 'finally', 'be', 'launched', 'at', 'the', 'event', 'google', 'assistant', 'as', 'it', 'sounds', 'is', 'very', 'much', 'advanced', 'form', 'of', 'google', 'now', 'so', 'google', 'might', 'bring', 'an', 'end', 'to', 'the', 'google', 'now', 'but', 'till', 'now', 'no', 'official', 'reports', 'have', 'been', 'made', 'for', 'such', 'news', 'android', 'google', 'allo', 'google', 'assistant', 'google', 'home', 'ios']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r'http\\S+', '', sent) # remove http\n",
    "        sent = re.sub(r'https\\S+', '', sent) # remove https\n",
    "        sent = re.sub('<[^>]+>', '', sent) # remove HTML tags\n",
    "        sent = re.sub('<[^<]+?>', '', sent)\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = re.sub(r'[^\\w\\s]','',sent) # remove punctuations\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), min_len=2, deacc=True) \n",
    "        \n",
    "        yield(sent)  \n",
    "\n",
    "# # Convert to list\n",
    "data = df.content.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291e451a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['google_assistant', 'work', 'recently', 'google', 'launch', 'product', 'google_assistant', 'caliber', 'take', 'tech', 'market', 'google', 'plan', 'go', 'face', 'face', 'apple', 'siri', 'amazon', 'alexa', 'due', 'fear', 'lose', 'market', 'artificial', 'intelligenceai', 'google', 'come', 'innovative', 'user', 'friendly', 'product', 'know', 'google_assistant', 'take', 'upgrade', 'version', 'google', 'google', 'many', 'things_like', 'search', 'important', 'feature', 'google', 'card', 'show', 'useful', 'information', 'almost', 'need', 'annual', 'google_io', 'developer', 'conference', 'google', 'talk', 'google_assistant', 'main', 'motive', 'new', 'virtual', 'assistant', 'see', 'improvement', 'google', 'way', 'conversation', 'experience', 'doubt', 'thing', 'talk', 'till', 'worry', 'discuss', 'detail', 'google_assistant', 'google_assistant', 'new', 'virtual', 'assistant', 'google', 'see', 'improvise', 'version', 'current', 'google_assistant', 'see', 'upgrade', 'extended', 'version', 'google', 'first', 'assistant', 'get', 'popular', 'market', 'apple', 'siri', 'since', 'google', 'work', 'upon', 'project', 'ceo', 'google', 'sundar', 'pichai', 'say', 'google', 'want', 'people', 'experience', 'twoway', 'conversation', 'virtual', 'assistant', 'keeping', 'mind', 'google', 'follow', 'path', 'apple', 'siri', 'siri', 'siri', 'understand', 'like', 'assistant', 'almost', 'want', 'weather', 'report', 'set', 'alarm', 'get', 'live', 'score', 'trend', 'news', 'siri', 'command', 'keep', 'siri', 'available', 'ios', 'google', 'introduce', 'google', 'android', 'fact', 'personal', 'handy', 'siri', 'feature', 'google', 'card', 'fetch', 'last', 'information', 'need', 'google', 'significant', 'feature', 'scanning', 'mail', 'list', 'track', 'order', 'important', 'date', 'many', 'things_like', 'siri', 'ios', 'google', 'android', 'alexa', 'amazon_alexa', 'limit', 'ios', 'android', 'make', 'special', 'find', 'company', 'connect', 'bluetooth_speaker', 'know', 'amazon_echo', 'since', 'launch', 'year', 'amazon_echo', 'let', 'unlimited', 'things_like', 'order', 'pizza', 'pay', 'bill', 'book', 'uber', 'keeping', 'check', 'connect', 'device', 'alexa', 'gain', 'much', 'popularity', 'small', 'time', 'need', 'launch', 'different', 'version', 'inspire', 'google', 'launch', 'product', 'call', 'google_home', 'annual', 'google_io', 'developer', 'conference', 'quite', 'similar', 'amazing', 'advantage', 'power', 'google_assistant', 'conference', 'google', 'explain', 'assistant', 'assistant', 'conversational', 'ongoing', 'twoway', 'dialogue', 'google', 'understand', 'world', 'help', 'get', 'thing', 'make', 'easy', 'buy', 'movie', 'ticket', 'go', 'find', 'perfect', 'restaurant', 'family', 'grab', 'quick', 'bite', 'movie', 'start', 'help', 'navigate', 'theater', 'science', 'make', 'computer', 'work', 'human', 'require', 'intelligence', 'think', 'ai', 'definitely', 'achieve', 'success', 'recent', 'past', 'limited', 'niche', 'domain', 'since', 'evolution', 'ai', 'year', 'back', 'much', 'advancement', 'come', 'ai', 'slow', 'growth', 'rate', 'ai', 'see', 'achieve', 'humanlevel', 'intelligence', 'easy', 'task', 'benefit', 'accurate', 'precise', 'chance', 'error', 'almost', 'nil', 'intelligent', 'machine', 'replace', 'human', 'many', 'area', 'work', 'robot', 'help', 'ai', 'certain', 'difficult', 'task', 'long', 'carry', 'human', 'possible', 'intelligence', 'program', 'machine', 'hold', 'great', 'program', 'manage', 'many', 'organisation', 'use', 'digital', 'assistant', 'interact', 'user', 'increase', 'enhance', 'customer', 'support', 'play', 'computer', 'game', 'fact', 'interact', 'game', 'computer', 'play', 'opponent', 'help', 'ai', 'machine', 'plan', 'game', 'move', 'response', 'thus', 'game', 'common', 'exle', 'advantage', 'great', 'advantage', 'machine', 'require', 'sleep', 'break', 'able', 'function', 'stop', 'continuously', 'perform', 'task', 'get', 'bored', 'tired', 'employ', 'carry', 'dangerous', 'task', 'risk', 'human', 'health', 'safety', 'reduce', 'google_assistant', 'work', 'google_assistant', 'artificial', 'intelligenceai', 'work', 'way', 'ask_question', 'throw', 'follow', 'question', 'upon', 'answer', 'question', 'keep', 'record', 'whole', 'conversation', 'end', 'processing', 'determine', 'whole', 'situation', 'display', 'good', 'answer', 'much', 'working', 'feature', 'know', 'till', 'present', 'know', 'sure', 'come', 'product', 'call', 'google_allo', 'google_home', 'google_allo', 'google_allo', 'allo', 'new', 'messaging', 'app', 'launch', 'google', 'ios', 'android', 'platform', 'call', 'messaging', 'app', 'wrong', 'many', 'feature', 'go', 'give', 'messaging', 'giant', 'tough', 'competition', 'introduce', 'google_io', 'conference', 'provide', 'messaging', 'feature', 'make', 'chat', 'attractive', 'interactive', 'idea', 'whatsapp', 'use', 'phone_number', 'start', 'already', 'google_account', 'add', 'android', 'automatically', 'add', 'profile', 'fllowe', 'footmark', 'messenger', 'feature', 'emojis', 'speaker', 'make', 'chat', 'fun', 'apart', 'google_assistant', 'still', 'remain', 'hot', 'feature', 'see', 'facebook_messenger', 'virtual', 'assistant', 'bot', 'use', 'google', 'thing', 'combine', 'assistant', 'bot', 'single', 'product', 'ask_questions', 'allo', 'simply', 'type', 'google', 'follow', 'question', 'dictate', 'question', 'voice', 'mode', 'google_assistant', 'ask', 'follow', 'question', 'fully', 'aware', 'context', 'respond', 'back', 'good', 'answer', 'let', 'exle', 'learn', 'google_assistant', 'case', 'go', 'new', 'place', 'city', 'need', 'find', 'good', 'hotel', 'area', 'good', 'food', 'point', 'map', 'whole', 'city', 'case', 'google_assistant', 'help', 'potential', 'case', 'bore', 'tired', 'simply', 'ask_google_assistant', 'joke', 'meme', 'funny', 'video', 'search', 'best', 'available', 'google', 'like', 'facebook_messenger', 'feature', 'gaming', 'type', 'google', 'lets', 'play', 'game', 'get', 'option', 'play', 'games', 'allo', 'fulloffun', 'app', 'google_assistant', 'make', 'experience', 'better', 'allo', 'incognito', 'mode', 'make', 'chat', 'private', 'chat', 'make', 'selfdestruct', 'specific', 'timeicoginito', 'feature', 'google_allo', 'google_home', 'google_home', 'google_home', 'like', 'amazon_echo', 'wifi', 'speaker', 'act', 'assistant', 'whole', 'family', 'smarthome', 'control', 'centre', 'apart', 'entertainment', 'device', 'whole', 'house', 'help', 'manage', 'everyday', 'task', 'ask_questions', 'google', 'possible', 'help', 'google_assistant', 'google_assistant', 'use', 'machine', 'learning', 'determine', 'situation', 'question', 'exle', 'type', 'let', 'watch', 'legend', 'tarzan', 'show', 'result', 'ticket', 'booking', 'website', 'ask', 'legend', 'tarzan', 'good', 'show', 'review', 'movie', 'trailer', 'rating', 'various', 'capability', 'compile', 'question', 'together', 'show', 'favorable', 'result', 'basic', 'things_like', 'maintain', 'daily', 'schedule', 'commute', 'working', 'time', 'many', 'fascinating', 'thing', 'help', 'google_assistant', 'integration', 'company', 'give', 'functionality', 'control', 'center', 'home', 'give_us', 'various', 'benefit', 'like', 'set', 'alarm', 'maintain', 'todo_list', 'connect', 'smarthome', 'lead', 'global', 'network', 'system', 'mean', 'able', 'control', 'fan', 'light', 'door', 'near', 'future', 'google', 'planning', 'work', 'developer', 'ease', 'work', 'exle', 'book', 'car', 'tour', 'send', 'card', 'flower', 'beloved', 'one', 'order', 'dinner', 'online', 'think', 'benefit', 'still', 'thing', 'online', 'answer', 'help', 'voice', 'dont_need', 'click', 'excessively', 'pay', 'every_time', 'alexa', 'already', 'integrate', 'big', 'third_party', 'application', 'software', 'like', 'spotify', 'iftt', 'uber', 'dominoe', 'phillips', 'belkin', 'many', 'see', 'apple', 'announce', 'release', 'siri', 'speaker', 'open', 'third_party', 'developer', 'google_assistant', 'work', 'third_party', 'integration', 'use_google_assistant', 'google_assistant', 'easily', 'access', 'enjoy', 'google_allo', 'app', 'already', 'available', 'playstore', 'google', 'assure', 'available', 'google', 'ecosystem', 'october', 'major', 'product', 'launch', 'long', 'await', 'pixel_phones', 'router', 'finally', 'launch', 'event', 'google_assistant', 'sound', 'much', 'advanced', 'form', 'google', 'google', 'bring', 'end', 'google', 'till', 'official', 'report', 'make', 'news', 'android', 'google_allo', 'google_assistant', 'google_home', 'ios']]\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=1,delimiter='_') # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=1, delimiter='_')  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Tag   Meaning                English Examples\n",
    "# ADJ   adjective              new, good, high, special, big, local\n",
    "# ADP   adposition             on, of, at, with, by, into, under\n",
    "# ADV   adverb                 really, already, still, early, now\n",
    "# CONJ  conjunction            and, or, but, if, while, although\n",
    "# DET   determiner, article    the, a, some, most, every, no, which\n",
    "# NOUN  noun                   year, home, costs, time, Africa\n",
    "# NUM   numeral                twenty-four, fourth, 1991, 14:24\n",
    "# PRT   particle               at, on, out, over per, that, up, with\n",
    "# PRON  pronoun                he, their, her, its, my, I, us\n",
    "# VERB  verb                   is, say, told, given, playing, would\n",
    "# .     punctuation marks      . , ; !\n",
    "# X     other                  ersatz, esprit, dunno, gr8, univeristy\n",
    "\n",
    "# def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "def process_words(texts, stop_words=stop_words, disallowed_postags=['ADP', 'CONJ', 'DET', 'NUM', 'PRT','PRON','.','X']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ not in disallowed_postags])\n",
    "#         texts_out.append([token.lemma_ for token in doc])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), max_len=20) if word not in stop_words] for doc in texts_out] \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n",
    "print(data_ready[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e07758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 10770\n",
      "Number of unique words after removing rare and common words: 1087\n",
      "Number of documents: 3021\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = Dictionary(data_ready)\n",
    "print('Number of unique words in initital documents:', len(id2word))\n",
    "\n",
    "# Filter out words that occur less than 0.5% documents, or more than 20% of the documents.\n",
    "id2word.filter_extremes(no_below = (round(((len(data_ready))*0.005))), no_above = 0.99)\n",
    "print('Number of unique words after removing rare and common words:', len(id2word))\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd973767",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.save(\"corpus_dict/dict\")\n",
    "corpora.MmCorpus.serialize(\"corpus_dict/corpus\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e225b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5447ao</td>\n",
       "      <td>What is Google Assistant and how does it work?</td>\n",
       "      <td>Recently, Google launched a product Google Ass...</td>\n",
       "      <td>https://www.reddit.com/r/googleassistant/comme...</td>\n",
       "      <td>TricksNDeals</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-23 19:18:25</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/googleassistant/comments/5447ao/what_is_goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>what is google assistant and how does it work ...</td>\n",
       "      <td>[able, access, achieve, act, add, ai, alarm, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                           title  \\\n",
       "0  5447ao  What is Google Assistant and how does it work?   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Recently, Google launched a product Google Ass...   \n",
       "\n",
       "                                           full_link        author  score  \\\n",
       "0  https://www.reddit.com/r/googleassistant/comme...  TricksNDeals      2   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-09-23 19:18:25                0   \n",
       "\n",
       "                                           permalink flair comment_msg  \\\n",
       "0  /r/googleassistant/comments/5447ao/what_is_goo...   NaN     ['nan']   \n",
       "\n",
       "                                             content  \\\n",
       "0  what is google assistant and how does it work ...   \n",
       "\n",
       "                                              tokenz  \n",
       "0  [able, access, achieve, act, add, ai, alarm, a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenz'] = [[(id2word[id]) for id, freq in cp] for cp in corpus[:]]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725c3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1_df_content_tokenz.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c40158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('able', 2), ('access', 1), ('achieve', 2), ('act', 1), ('add', 2), ('ai', 6), ('alarm', 2), ('alexa', 4), ('almost', 3), ('already', 3), ('amazing', 1), ('amazon', 1), ('android', 6), ('announce', 1), ('answer', 4), ('app', 4), ('apple', 4), ('application', 1), ('area', 2), ('ask', 2), ('ask_google_assistant', 1), ('ask_question', 1), ('assistant', 11), ('automatically', 1), ('available', 4), ('aware', 1), ('back', 2), ('basic', 1), ('best', 1), ('better', 1), ('big', 1), ('book', 2), ('bot', 2), ('break', 1), ('bring', 1), ('buy', 1), ('call', 3), ('car', 1), ('card', 3), ('case', 3), ('certain', 1), ('chance', 1), ('check', 1), ('click', 1), ('come', 3), ('command', 1), ('common', 1), ('commute', 1), ('company', 2), ('computer', 3), ('connect', 3), ('control', 3), ('conversation', 3), ('current', 1), ('daily', 1), ('date', 1), ('definitely', 1), ('detail', 1), ('developer', 4), ('device', 2), ('different', 1), ('display', 1), ('dont_need', 1), ('door', 1), ('due', 1), ('easily', 1), ('easy', 2), ('end', 2), ('enjoy', 1), ('error', 1), ('event', 1), ('every_time', 1), ('exle', 4), ('experience', 3), ('explain', 1), ('face', 2), ('fact', 2), ('family', 2), ('fan', 1), ('feature', 10), ('finally', 1), ('find', 3), ('first', 1), ('follow', 4), ('form', 1), ('fully', 1), ('fun', 1), ('function', 1), ('functionality', 1), ('funny', 1), ('future', 1), ('game', 5), ('get', 5), ('give', 2), ('go', 4), ('good', 5), ('google', 34), ('google_account', 1), ('google_assistant', 22), ('google_home', 6), ('great', 2), ('help', 9), ('hold', 1), ('home', 1), ('house', 1), ('idea', 1), ('important', 2), ('information', 2), ('integrate', 1), ('integration', 2), ('interact', 2), ('ios', 5), ('joke', 1), ('keep', 2), ('know', 4), ('last', 1), ('launch', 7), ('lead', 1), ('learn', 1), ('let', 3), ('light', 1), ('like', 5), ('limit', 1), ('limited', 1), ('list', 1), ('live', 1), ('long', 2), ('lose', 1), ('main', 1), ('make', 9), ('manage', 2), ('many', 7), ('map', 1), ('mean', 1), ('mind', 1), ('mode', 2), ('move', 1), ('movie', 3), ('much', 4), ('navigate', 1), ('near', 1), ('need', 4), ('network', 1), ('new', 4), ('news', 2), ('one', 1), ('online', 2), ('open', 1), ('option', 1), ('order', 3), ('past', 1), ('pay', 2), ('people', 1), ('perform', 1), ('personal', 1), ('place', 1), ('plan', 2), ('platform', 1), ('play', 4), ('point', 1), ('popular', 1), ('possible', 2), ('power', 1), ('product', 6), ('profile', 1), ('program', 2), ('project', 1), ('provide', 1), ('question', 7), ('quick', 1), ('quite', 1), ('recent', 1), ('recently', 1), ('record', 1), ('release', 1), ('replace', 1), ('report', 2), ('require', 2), ('respond', 1), ('response', 1), ('result', 2), ('review', 1), ('say', 1), ('schedule', 1), ('search', 2), ('see', 6), ('send', 1), ('set', 2), ('show', 4), ('similar', 1), ('simply', 2), ('since', 3), ('single', 1), ('siri', 10), ('situation', 2), ('sleep', 1), ('slow', 1), ('small', 1), ('software', 1), ('sound', 1), ('speaker', 3), ('special', 1), ('specific', 1), ('spotify', 1), ('start', 2), ('still', 2), ('stop', 1), ('success', 1), ('support', 1), ('sure', 1), ('system', 1), ('take', 2), ('talk', 2), ('task', 5), ('tech', 1), ('thing', 5), ('things_like', 4), ('think', 2), ('third_party', 3), ('time', 2), ('tired', 2), ('together', 1), ('track', 1), ('type', 3), ('understand', 2), ('upgrade', 2), ('upon', 2), ('use', 4), ('use_google_assistant', 1), ('useful', 1), ('user', 2), ('various', 2), ('version', 4), ('video', 1), ('voice', 2), ('want', 2), ('watch', 1), ('way', 2), ('weather', 1), ('website', 1), ('whatsapp', 1), ('whole', 5), ('wifi', 1), ('work', 9), ('working', 2), ('world', 1), ('wrong', 1), ('year', 2)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a359b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)\n",
    "#     break\n",
    "\n",
    "# # print('Number of unique tokens: %d' % len(id2word))\n",
    "# # print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71f696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topWords = {}\n",
    "# for doc in corpus:\n",
    "#     for iWord, tf_idf in doc:\n",
    "#         if iWord not in topWords:\n",
    "#             topWords[iWord] = 0\n",
    "\n",
    "#         if tf_idf > topWords[iWord]:\n",
    "#             topWords[iWord] = tf_idf\n",
    "# sum = 0\n",
    "# term = []\n",
    "# for i, item in enumerate(sorted(topWords.items(), key=lambda x: x[1], reverse=True), 1):\n",
    "# #     print(\"%2s: %-13s %s\" % (i, id2word[item[0]], item[1]))\n",
    "#     term.append(id2word[item[0]])\n",
    "#     sum += item[1]\n",
    "# #     if i == 100: break\n",
    "# # print (sum)\n",
    "# mean = sum/i\n",
    "# print ('Mean of tf-idf score: ' + str(mean))\n",
    "# # print (term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab5fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# low_value = 0.271734994034526\n",
    "# low_value_words = []\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     low_value_words += [id for id, value in tfidf[doc] if value < low_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0570e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word.filter_tokens(bad_ids=low_value_words)\n",
    "# print('Number of filtered unique tokens: %d' % len(id2word))\n",
    "# print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b5169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [id2word.doc2bow(doc) for doc in data_ready]\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9362c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99833368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=10)\n",
    "\n",
    "# pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "407e52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, num_topics, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=num_topics, \n",
    "                                                random_state=100,\n",
    "                                                chunksize=100,\n",
    "                                                passes=40,\n",
    "                                                iterations=1000,\n",
    "                                                alpha=a,\n",
    "                                                eta=1/num_topics,\n",
    "                                                eval_every=None)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['tokenz'], dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0095c6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_1 = pd.DataFrame(model_results)\n",
    "model_results_1.to_csv('tuning/00_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e000282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_2 = pd.DataFrame(model_results)\n",
    "model_results_2.to_csv('tuning/11_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04caa38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_3 = pd.DataFrame(model_results)\n",
    "model_results_3.to_csv('tuning/22_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50a69dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_4 = pd.DataFrame(model_results)\n",
    "model_results_4.to_csv('tuning/33_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c4ada8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_5 = pd.DataFrame(model_results)\n",
    "model_results_5.to_csv('tuning/44_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31688b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_6 = pd.DataFrame(model_results)\n",
    "model_results_6.to_csv('tuning/55_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67388506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_7 = pd.DataFrame(model_results)\n",
    "model_results_7.to_csv('tuning/66_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90322922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_8 = pd.DataFrame(model_results)\n",
    "model_results_8.to_csv('tuning/77_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36df0196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_9 = pd.DataFrame(model_results)\n",
    "model_results_9.to_csv('tuning/88_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02daa493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.5267041879488744\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.5255925037964797\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5222324395553346\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.5700077763053673\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6070406397399928\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.6087348690047772\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.46230994156252275\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.47100868112304184\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.4645652436245665\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.45068854320280816\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.5386711743273569\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.5905648087936453\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.37419160074902696\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.4036052238359666\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.39344677109201076\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4141246498303642\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44710526955742225\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.4593533697380291\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.4080856618215486\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.41045594125848694\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4037927010196475\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.38635844119574325\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3409825088934663\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.3825148046459521\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_10 = pd.DataFrame(model_results)\n",
    "model_results_10.to_csv('tuning/99_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d39207cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.concat([model_results_1, model_results_2, model_results_3, model_results_4, model_results_5,\n",
    "                          model_results_6, model_results_7, model_results_8, model_results_9, model_results_10])\n",
    "model_results.to_csv(\"tuning/model_results.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c83c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.groupby(['Topics', 'Alpha'], as_index=False).mean()\n",
    "model_results = model_results.sort_values(by='Coherence', ascending=False)\n",
    "model_results.to_csv('2_lda_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aa9e9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.608735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.607041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.590565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.570008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.538671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.526704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.525593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.522232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.471009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.464565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.462310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.459353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.450689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.447105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.414125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.410456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.408086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.403793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.403605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.393447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.386358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.382515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.374192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.340983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topics  Alpha      Beta  Coherence\n",
       "5        5   1.00  0.200000   0.608735\n",
       "4        5   0.50  0.200000   0.607041\n",
       "11      10   1.00  0.100000   0.590565\n",
       "3        5   0.20  0.200000   0.570008\n",
       "10      10   0.50  0.100000   0.538671\n",
       "0        5   0.01  0.200000   0.526704\n",
       "1        5   0.05  0.200000   0.525593\n",
       "2        5   0.10  0.200000   0.522232\n",
       "7       10   0.05  0.100000   0.471009\n",
       "8       10   0.10  0.100000   0.464565\n",
       "6       10   0.01  0.100000   0.462310\n",
       "17      20   1.00  0.050000   0.459353\n",
       "9       10   0.20  0.100000   0.450689\n",
       "16      20   0.50  0.050000   0.447105\n",
       "15      20   0.20  0.050000   0.414125\n",
       "19      30   0.05  0.033333   0.410456\n",
       "18      30   0.01  0.033333   0.408086\n",
       "20      30   0.10  0.033333   0.403793\n",
       "13      20   0.05  0.050000   0.403605\n",
       "14      20   0.10  0.050000   0.393447\n",
       "21      30   0.20  0.033333   0.386358\n",
       "23      30   1.00  0.033333   0.382515\n",
       "12      20   0.01  0.050000   0.374192\n",
       "22      30   0.50  0.033333   0.340983"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "635d9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = pd.pivot_table(model_results,index=[\"Topics\"],columns=[\"Alpha\"],values=['Coherence'])\n",
    "# priors.columns = range(priors.shape[1])\n",
    "# priors.columns = ['.01','.05','.1','.2','.5','1']\n",
    "# df.head(1)\n",
    "# priors = priors.reset_index()\n",
    "# priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4792b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors.to_csv(\"siri_lda_tuning_results.csv\",index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "641721be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "  \n",
    "# # dummy data\n",
    "# x1 = priors['Topics']\n",
    "# A = priors['.01']\n",
    "# B = priors['.05']\n",
    "# C = priors['.1']\n",
    "# D = priors['.2']\n",
    "# E = priors['.5']\n",
    "# F = priors['1']\n",
    "\n",
    "# # creates two subplots\n",
    "# # fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (24, 12))\n",
    "\n",
    "# fig, ax = plt.subplots(2, 3, figsize = (24,12))\n",
    "\n",
    "# # Plot without grid\n",
    "# ax[0,0].plot(x1, A, label='0.01', color='tab:blue')\n",
    "# ax[0,1].plot(x1, B, label='0.05', color='tab:orange')\n",
    "# ax[0,2].plot(x1, C, label='0.1', color='tab:green')\n",
    "# ax[1,0].plot(x1, D, label='0.2', color='tab:red')\n",
    "# ax[1,1].plot(x1, E, label='0.5', color='tab:purple')\n",
    "# ax[1,2].plot(x1, F, label='1', color='tab:brown')\n",
    "\n",
    "# ax[0,0].set_xlim(xmin=9)\n",
    "# ax[0,0].set_title('siri, Î±=.01, Beta=1/K')\n",
    "# ax[0,0].set_xlabel('K')\n",
    "# ax[0,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,1].set_xlim(xmin=9)\n",
    "# ax[0,1].set_title('siri, Î±=.05, Beta=1/K')\n",
    "# ax[0,1].set_xlabel('K')\n",
    "# ax[0,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,2].set_xlim(xmin=9)\n",
    "# ax[0,2].set_title('siri, Î±=.1, Beta=1/K')\n",
    "# ax[0,2].set_xlabel('K')\n",
    "# ax[0,2].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,0].set_xlim(xmin=9)\n",
    "# ax[1,0].set_title('siri, Î±=.2, Beta=1/K')\n",
    "# ax[1,0].set_xlabel('K')\n",
    "# ax[1,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,1].set_xlim(xmin=9)\n",
    "# ax[1,1].set_title('siri, Î±=.5, Beta=1/K')\n",
    "# ax[1,1].set_xlabel('K')\n",
    "# ax[1,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,2].set_xlim(xmin=9)\n",
    "# ax[1,2].set_title('siri, Î±=1, Beta=1/K')\n",
    "# ax[1,2].set_xlabel('K')\n",
    "# ax[1,2].set_ylabel('Cv')\n",
    "\n",
    "# # fig.tight_layout()\n",
    "# fig.set_facecolor(\"w\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
