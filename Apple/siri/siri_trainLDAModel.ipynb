{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a37e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "from cleantext import clean\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['https_www','seems_like','do','not','imgur','tkg','https','http','could','www','com','ever','doesnt_seem',\n",
    "                  'xxxx','else','would','also','ea','&amp','#x200B','oh','etc','yeah','nan','however','even','dont_know','sa',\n",
    "                  \"looks_like\",'especially','may','sounds_like'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e97f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2235, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lzda4</td>\n",
       "      <td>Apple is working on an AI system that wipes th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4lzda4/...</td>\n",
       "      <td>dunkin1980</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-06-01 11:54:39</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/Siri/comments/4lzda4/apple_is_working_on_an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Man I hope they don't screw this up.,If so, ...</td>\n",
       "      <td>Apple is working on an AI system that wipes th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                              title selftext  \\\n",
       "0  4lzda4  Apple is working on an AI system that wipes th...      NaN   \n",
       "\n",
       "                                           full_link      author  score  \\\n",
       "0  https://www.reddit.com/r/Siri/comments/4lzda4/...  dunkin1980      6   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-06-01 11:54:39                2   \n",
       "\n",
       "                                           permalink  flair  \\\n",
       "0  /r/Siri/comments/4lzda4/apple_is_working_on_an...    NaN   \n",
       "\n",
       "                                         comment_msg  \\\n",
       "0  [\"Man I hope they don't screw this up.,If so, ...   \n",
       "\n",
       "                                             content  \n",
       "0  Apple is working on an AI system that wipes th...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoadDataset\n",
    "df=pd.read_csv('siri_merged.csv')\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2017df74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lzda4</td>\n",
       "      <td>Apple is working on an AI system that wipes th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4lzda4/...</td>\n",
       "      <td>dunkin1980</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-06-01 11:54:39</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/Siri/comments/4lzda4/apple_is_working_on_an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Man I hope they don't screw this up.,If so, ...</td>\n",
       "      <td>apple is working on an ai system that wipes th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4lzi6i</td>\n",
       "      <td>I asked my 5S Siri to flip a coin for me, had ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4lzi6i/...</td>\n",
       "      <td>JangoBK</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-06-01 12:32:01</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/Siri/comments/4lzi6i/i_asked_my_5s_siri_to_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"http://imgur.com/tKg26ea\\n\\nShe doesn't have...</td>\n",
       "      <td>i asked my s siri to flip a coin for me had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4m2z9l</td>\n",
       "      <td>If Apple's latest commercial was honest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4m2z9l/...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-06-02 03:15:08</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/Siri/comments/4m2z9l/if_apples_latest_comme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>if apples latest commercial was honest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4m3w5b</td>\n",
       "      <td>Worldwide exclusive interview with Siri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4m3w5b/...</td>\n",
       "      <td>tinycomet</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-02 06:13:25</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/Siri/comments/4m3w5b/worldwide_exclusive_in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>worldwide exclusive interview with siri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4m5buw</td>\n",
       "      <td>Siri responds to AT&amp;amp;T \"Hostess with the Mo...</td>\n",
       "      <td>When Lily (in the commercial) says \"OK Siri\", ...</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4m5buw/...</td>\n",
       "      <td>unsubscribe__</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-02 11:54:11</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/Siri/comments/4m5buw/siri_responds_to_att_h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>siri responds to att hostess with the mostest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>nk8f2b</td>\n",
       "      <td>So I was just sitting talking about AI with my...</td>\n",
       "      <td>Anyone who can explain how this is possible? I...</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/nk8f2b/...</td>\n",
       "      <td>ridiculus97</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-25 05:06:42</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/Siri/comments/nk8f2b/so_i_was_just_sitting_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"She's just trying to include herself in the ...</td>\n",
       "      <td>so i was just sitting talking about ai with my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2231</td>\n",
       "      <td>nmys6b</td>\n",
       "      <td>Long time problem with Siri: While listening t...</td>\n",
       "      <td>It will not switch to the Podcasts app nor wil...</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/nmys6b/...</td>\n",
       "      <td>ThunderHawkLives</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-28 22:15:45</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/Siri/comments/nmys6b/long_time_problem_with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>long time problem with siri while listening to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2232</td>\n",
       "      <td>nns10e</td>\n",
       "      <td>My default search engine is DuckDuckGo on Safa...</td>\n",
       "      <td>I checked Siri settings, there is no option fo...</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/nns10e/...</td>\n",
       "      <td>hemeka</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-30 01:20:41</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/Siri/comments/nns10e/my_default_search_engi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>my default search engine is duckduckgo on safa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2233</td>\n",
       "      <td>nns990</td>\n",
       "      <td>I can not set default search engine on Siri.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/nns990/...</td>\n",
       "      <td>hemeka</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-30 01:32:08</td>\n",
       "      <td>3</td>\n",
       "      <td>/r/Siri/comments/nns990/i_can_not_set_default_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"You can't change Siri's settings, Google pay...</td>\n",
       "      <td>i can not set default search engine on siri yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2234</td>\n",
       "      <td>np6ozt</td>\n",
       "      <td>Siri confusing summer and winter. iPhone 11 on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/np6ozt/...</td>\n",
       "      <td>magnificent_manu</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-31 23:59:12</td>\n",
       "      <td>5</td>\n",
       "      <td>/r/Siri/comments/np6ozt/siri_confusing_summer_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['You live on the Southern Hemisphere and so i...</td>\n",
       "      <td>siri confusing summer and winter iphone on ios...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                              title  \\\n",
       "0     4lzda4  Apple is working on an AI system that wipes th...   \n",
       "1     4lzi6i  I asked my 5S Siri to flip a coin for me, had ...   \n",
       "2     4m2z9l         If Apple's latest commercial was honest...   \n",
       "3     4m3w5b            Worldwide exclusive interview with Siri   \n",
       "4     4m5buw  Siri responds to AT&amp;T \"Hostess with the Mo...   \n",
       "...      ...                                                ...   \n",
       "2230  nk8f2b  So I was just sitting talking about AI with my...   \n",
       "2231  nmys6b  Long time problem with Siri: While listening t...   \n",
       "2232  nns10e  My default search engine is DuckDuckGo on Safa...   \n",
       "2233  nns990       I can not set default search engine on Siri.   \n",
       "2234  np6ozt  Siri confusing summer and winter. iPhone 11 on...   \n",
       "\n",
       "                                               selftext  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4     When Lily (in the commercial) says \"OK Siri\", ...   \n",
       "...                                                 ...   \n",
       "2230  Anyone who can explain how this is possible? I...   \n",
       "2231  It will not switch to the Podcasts app nor wil...   \n",
       "2232  I checked Siri settings, there is no option fo...   \n",
       "2233                                                NaN   \n",
       "2234                                                NaN   \n",
       "\n",
       "                                              full_link            author  \\\n",
       "0     https://www.reddit.com/r/Siri/comments/4lzda4/...        dunkin1980   \n",
       "1     https://www.reddit.com/r/Siri/comments/4lzi6i/...           JangoBK   \n",
       "2     https://www.reddit.com/r/Siri/comments/4m2z9l/...         [deleted]   \n",
       "3     https://www.reddit.com/r/Siri/comments/4m3w5b/...         tinycomet   \n",
       "4     https://www.reddit.com/r/Siri/comments/4m5buw/...     unsubscribe__   \n",
       "...                                                 ...               ...   \n",
       "2230  https://www.reddit.com/r/Siri/comments/nk8f2b/...       ridiculus97   \n",
       "2231  https://www.reddit.com/r/Siri/comments/nmys6b/...  ThunderHawkLives   \n",
       "2232  https://www.reddit.com/r/Siri/comments/nns10e/...            hemeka   \n",
       "2233  https://www.reddit.com/r/Siri/comments/nns990/...            hemeka   \n",
       "2234  https://www.reddit.com/r/Siri/comments/np6ozt/...  magnificent_manu   \n",
       "\n",
       "      score         publish_date  num_of_comments  \\\n",
       "0         6  2016-06-01 11:54:39                2   \n",
       "1         7  2016-06-01 12:32:01                1   \n",
       "2         6  2016-06-02 03:15:08                0   \n",
       "3         1  2016-06-02 06:13:25                0   \n",
       "4         1  2016-06-02 11:54:11                0   \n",
       "...     ...                  ...              ...   \n",
       "2230      1  2021-05-25 05:06:42                2   \n",
       "2231      1  2021-05-28 22:15:45                0   \n",
       "2232      1  2021-05-30 01:20:41                0   \n",
       "2233      1  2021-05-30 01:32:08                3   \n",
       "2234      2  2021-05-31 23:59:12                5   \n",
       "\n",
       "                                              permalink  flair  \\\n",
       "0     /r/Siri/comments/4lzda4/apple_is_working_on_an...    NaN   \n",
       "1     /r/Siri/comments/4lzi6i/i_asked_my_5s_siri_to_...    NaN   \n",
       "2     /r/Siri/comments/4m2z9l/if_apples_latest_comme...    NaN   \n",
       "3     /r/Siri/comments/4m3w5b/worldwide_exclusive_in...    NaN   \n",
       "4     /r/Siri/comments/4m5buw/siri_responds_to_att_h...    NaN   \n",
       "...                                                 ...    ...   \n",
       "2230  /r/Siri/comments/nk8f2b/so_i_was_just_sitting_...    NaN   \n",
       "2231  /r/Siri/comments/nmys6b/long_time_problem_with...    NaN   \n",
       "2232  /r/Siri/comments/nns10e/my_default_search_engi...    NaN   \n",
       "2233  /r/Siri/comments/nns990/i_can_not_set_default_...    NaN   \n",
       "2234  /r/Siri/comments/np6ozt/siri_confusing_summer_...    NaN   \n",
       "\n",
       "                                            comment_msg  \\\n",
       "0     [\"Man I hope they don't screw this up.,If so, ...   \n",
       "1     [\"http://imgur.com/tKg26ea\\n\\nShe doesn't have...   \n",
       "2                                               ['nan']   \n",
       "3                                               ['nan']   \n",
       "4                                               ['nan']   \n",
       "...                                                 ...   \n",
       "2230  [\"She's just trying to include herself in the ...   \n",
       "2231                                            ['nan']   \n",
       "2232                                            ['nan']   \n",
       "2233  [\"You can't change Siri's settings, Google pay...   \n",
       "2234  ['You live on the Southern Hemisphere and so i...   \n",
       "\n",
       "                                                content  \n",
       "0     apple is working on an ai system that wipes th...  \n",
       "1     i asked my s siri to flip a coin for me had a ...  \n",
       "2               if apples latest commercial was honest   \n",
       "3              worldwide exclusive interview with siri   \n",
       "4     siri responds to att hostess with the mostest ...  \n",
       "...                                                 ...  \n",
       "2230  so i was just sitting talking about ai with my...  \n",
       "2231  long time problem with siri while listening to...  \n",
       "2232  my default search engine is duckduckgo on safa...  \n",
       "2233  i can not set default search engine on siri yo...  \n",
       "2234  siri confusing summer and winter iphone on ios...  \n",
       "\n",
       "[2235 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI)\n",
    "\n",
    "def preprocess_tweet(row):\n",
    "    text = row['content']\n",
    "    text = text.replace('r/','')\n",
    "    text = p.clean(text)\n",
    "    text = clean(text,     \n",
    "                 fix_unicode=True,              # fix various unicode errors\n",
    "                 to_ascii=True,                 # transliterate to closest ASCII representation\n",
    "                 lower=True,                    # lowercase text\n",
    "                 no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                 no_urls=True,                  # replace all URLs with a special token\n",
    "                 no_emails=True,                # replace all email addresses with a special token\n",
    "                 no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                 no_numbers=True,               # replace all numbers with a special token\n",
    "                 no_digits=True,                # replace all digits with a special token\n",
    "                 no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                 no_punct=True,                 # remove punctuations\n",
    "                 lang=\"en\",                     # set to 'de' for German special handling\n",
    "                 replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                 replace_with_url=\"\",\n",
    "                 replace_with_email=\"\",\n",
    "                 replace_with_phone_number=\"\",\n",
    "                 replace_with_number=\"\",\n",
    "                 replace_with_digit=\"\",\n",
    "                 replace_with_currency_symbol=\"\"\n",
    "                )\n",
    "    text = text.replace('amp','')\n",
    "    text = text.replace('nan','')\n",
    "    return text\n",
    "\n",
    "df['content'] = df.apply(preprocess_tweet, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6188fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'is', 'working', 'on', 'an', 'ai', 'system', 'that', 'wipes', 'the', 'floor', 'with', 'google', 'and', 'everyone', 'else', 'man', 'hope', 'they', 'dont', 'screw', 'this', 'upif', 'so', 'it', 'wasnt', 'announced', 'at', 'wwdc', 'and', 'doesnt', 'seem', 'to', 'be', 'in', 'ios', 'hopefully', 'we', 'wont', 'have', 'to', 'wait', 'until', 'ios', 'or', 'later', 'to', 'see', 'it', 'because', 'siri', 'is', 'useless', 'now', 'and', 'has', 'been', 'for', 'long', 'time']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r'http\\S+', '', sent) # remove http\n",
    "        sent = re.sub(r'https\\S+', '', sent) # remove https\n",
    "        sent = re.sub('<[^>]+>', '', sent) # remove HTML tags\n",
    "        sent = re.sub('<[^<]+?>', '', sent)\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = re.sub(r'[^\\w\\s]','',sent) # remove punctuations\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), min_len=2, deacc=True) \n",
    "        \n",
    "        yield(sent)  \n",
    "\n",
    "# # Convert to list\n",
    "data = df.content.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abde4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'work', 'ai', 'system', 'wipe', 'floor', 'google', 'everyone', 'man', 'hope', 'screw', 'upif', 'announce', 'wwdc', 'ios', 'hopefully', 'wait', 'later', 'see', 'siri', 'useless', 'long_time']]\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=1,delimiter='_') # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=1, delimiter='_')  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Tag   Meaning                English Examples\n",
    "# ADJ   adjective              new, good, high, special, big, local\n",
    "# ADP   adposition             on, of, at, with, by, into, under\n",
    "# ADV   adverb                 really, already, still, early, now\n",
    "# CONJ  conjunction            and, or, but, if, while, although\n",
    "# DET   determiner, article    the, a, some, most, every, no, which\n",
    "# NOUN  noun                   year, home, costs, time, Africa\n",
    "# NUM   numeral                twenty-four, fourth, 1991, 14:24\n",
    "# PRT   particle               at, on, out, over per, that, up, with\n",
    "# PRON  pronoun                he, their, her, its, my, I, us\n",
    "# VERB  verb                   is, say, told, given, playing, would\n",
    "# .     punctuation marks      . , ; !\n",
    "# X     other                  ersatz, esprit, dunno, gr8, univeristy\n",
    "\n",
    "# def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "def process_words(texts, stop_words=stop_words, disallowed_postags=['ADP', 'CONJ', 'DET', 'NUM', 'PRT','PRON','.','X']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ not in disallowed_postags])\n",
    "#         texts_out.append([token.lemma_ for token in doc])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), max_len=20) if word not in stop_words] for doc in texts_out] \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n",
    "print(data_ready[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9f7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 7629\n",
      "Number of unique words after removing rare and common words: 820\n",
      "Number of documents: 2235\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = Dictionary(data_ready)\n",
    "print('Number of unique words in initital documents:', len(id2word))\n",
    "\n",
    "# Filter out words that occur less than 0.5% documents, or more than 20% of the documents.\n",
    "id2word.filter_extremes(no_below = (round(((len(data_ready))*0.005))), no_above = 0.99)\n",
    "print('Number of unique words after removing rare and common words:', len(id2word))\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625d0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.save(\"corpus_dict/dict\")\n",
    "corpora.MmCorpus.serialize(\"corpus_dict/corpus\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56c207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lzda4</td>\n",
       "      <td>Apple is working on an AI system that wipes th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/Siri/comments/4lzda4/...</td>\n",
       "      <td>dunkin1980</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-06-01 11:54:39</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/Siri/comments/4lzda4/apple_is_working_on_an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Man I hope they don't screw this up.,If so, ...</td>\n",
       "      <td>apple is working on an ai system that wipes th...</td>\n",
       "      <td>[ai, announce, apple, google, hope, hopefully,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                              title selftext  \\\n",
       "0  4lzda4  Apple is working on an AI system that wipes th...      NaN   \n",
       "\n",
       "                                           full_link      author  score  \\\n",
       "0  https://www.reddit.com/r/Siri/comments/4lzda4/...  dunkin1980      6   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-06-01 11:54:39                2   \n",
       "\n",
       "                                           permalink  flair  \\\n",
       "0  /r/Siri/comments/4lzda4/apple_is_working_on_an...    NaN   \n",
       "\n",
       "                                         comment_msg  \\\n",
       "0  [\"Man I hope they don't screw this up.,If so, ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  apple is working on an ai system that wipes th...   \n",
       "\n",
       "                                              tokenz  \n",
       "0  [ai, announce, apple, google, hope, hopefully,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenz'] = [[(id2word[id]) for id, freq in cp] for cp in corpus[:]]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2022e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1_df_content_tokenz.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf748ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('ai', 1), ('announce', 1), ('apple', 1), ('google', 1), ('hope', 1), ('hopefully', 1), ('ios', 1), ('later', 1), ('long_time', 1), ('man', 1), ('see', 1), ('siri', 1), ('system', 1), ('useless', 1), ('wait', 1), ('work', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb217be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)\n",
    "#     break\n",
    "\n",
    "# # print('Number of unique tokens: %d' % len(id2word))\n",
    "# # print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29397e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topWords = {}\n",
    "# for doc in corpus:\n",
    "#     for iWord, tf_idf in doc:\n",
    "#         if iWord not in topWords:\n",
    "#             topWords[iWord] = 0\n",
    "\n",
    "#         if tf_idf > topWords[iWord]:\n",
    "#             topWords[iWord] = tf_idf\n",
    "# sum = 0\n",
    "# term = []\n",
    "# for i, item in enumerate(sorted(topWords.items(), key=lambda x: x[1], reverse=True), 1):\n",
    "# #     print(\"%2s: %-13s %s\" % (i, id2word[item[0]], item[1]))\n",
    "#     term.append(id2word[item[0]])\n",
    "#     sum += item[1]\n",
    "# #     if i == 100: break\n",
    "# # print (sum)\n",
    "# mean = sum/i\n",
    "# print ('Mean of tf-idf score: ' + str(mean))\n",
    "# # print (term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08770c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# low_value = 0.271734994034526\n",
    "# low_value_words = []\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     low_value_words += [id for id, value in tfidf[doc] if value < low_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de5d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word.filter_tokens(bad_ids=low_value_words)\n",
    "# print('Number of filtered unique tokens: %d' % len(id2word))\n",
    "# print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8e4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [id2word.doc2bow(doc) for doc in data_ready]\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000c6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e4204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=10)\n",
    "\n",
    "# pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e99772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, num_topics, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=num_topics, \n",
    "                                                random_state=100,\n",
    "                                                chunksize=100,\n",
    "                                                passes=40,\n",
    "                                                iterations=1000,\n",
    "                                                alpha=a,\n",
    "                                                eta=1/num_topics,\n",
    "                                                eval_every=None)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['tokenz'], dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d390ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_1 = pd.DataFrame(model_results)\n",
    "model_results_1.to_csv('tuning/00_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd33017b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_2 = pd.DataFrame(model_results)\n",
    "model_results_2.to_csv('tuning/11_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b1474f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_3 = pd.DataFrame(model_results)\n",
    "model_results_3.to_csv('tuning/22_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121b847d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_4 = pd.DataFrame(model_results)\n",
    "model_results_4.to_csv('tuning/33_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958e7eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_5 = pd.DataFrame(model_results)\n",
    "model_results_5.to_csv('tuning/44_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71e47ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_6 = pd.DataFrame(model_results)\n",
    "model_results_6.to_csv('tuning/55_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4c379b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_7 = pd.DataFrame(model_results)\n",
    "model_results_7.to_csv('tuning/66_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c06b5fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_8 = pd.DataFrame(model_results)\n",
    "model_results_8.to_csv('tuning/77_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30e9abab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_9 = pd.DataFrame(model_results)\n",
    "model_results_9.to_csv('tuning/88_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43a92ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6016461949722964\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6034813900035713\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.5846629674154018\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.553893964134093\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.668860293968037\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.695418050515428\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.51671445113345\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5315092553314879\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5384734432878137\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5461184029321892\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6253460472935441\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6559895048483556\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.4680231027918258\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.46113381470649656\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.4760800899091716\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.4632987362986919\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.44176104165882446\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.43589633755299617\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.42312646461950004\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.4137063548348686\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.4242686298931834\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.4009006394139174\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.3601669465594338\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.38665094275510115\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_10 = pd.DataFrame(model_results)\n",
    "model_results_10.to_csv('tuning/99_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aafaf460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.concat([model_results_1, model_results_2, model_results_3, model_results_4, model_results_5,\n",
    "                          model_results_6, model_results_7, model_results_8, model_results_9, model_results_10])\n",
    "model_results.to_csv(\"tuning/model_results.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c48acc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.groupby(['Topics', 'Alpha'], as_index=False).mean()\n",
    "model_results = model_results.sort_values(by='Coherence', ascending=False)\n",
    "model_results.to_csv('2_lda_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b749831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.695418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.668860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.655990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.625346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.603481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.601646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.584663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.553894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.546118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.538473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.531509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.516714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.476080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.468023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.463299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.461134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.441761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.435896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.424269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.423126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.413706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.400901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.386651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.360167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topics  Alpha      Beta  Coherence\n",
       "5        5   1.00  0.200000   0.695418\n",
       "4        5   0.50  0.200000   0.668860\n",
       "11      10   1.00  0.100000   0.655990\n",
       "10      10   0.50  0.100000   0.625346\n",
       "1        5   0.05  0.200000   0.603481\n",
       "0        5   0.01  0.200000   0.601646\n",
       "2        5   0.10  0.200000   0.584663\n",
       "3        5   0.20  0.200000   0.553894\n",
       "9       10   0.20  0.100000   0.546118\n",
       "8       10   0.10  0.100000   0.538473\n",
       "7       10   0.05  0.100000   0.531509\n",
       "6       10   0.01  0.100000   0.516714\n",
       "14      20   0.10  0.050000   0.476080\n",
       "12      20   0.01  0.050000   0.468023\n",
       "15      20   0.20  0.050000   0.463299\n",
       "13      20   0.05  0.050000   0.461134\n",
       "16      20   0.50  0.050000   0.441761\n",
       "17      20   1.00  0.050000   0.435896\n",
       "20      30   0.10  0.033333   0.424269\n",
       "18      30   0.01  0.033333   0.423126\n",
       "19      30   0.05  0.033333   0.413706\n",
       "21      30   0.20  0.033333   0.400901\n",
       "23      30   1.00  0.033333   0.386651\n",
       "22      30   0.50  0.033333   0.360167"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e72f908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = pd.pivot_table(model_results,index=[\"Topics\"],columns=[\"Alpha\"],values=['Coherence'])\n",
    "# priors.columns = range(priors.shape[1])\n",
    "# priors.columns = ['.01','.05','.1','.2','.5','1']\n",
    "# df.head(1)\n",
    "# priors = priors.reset_index()\n",
    "# priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f7e023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors.to_csv(\"siri_lda_tuning_results.csv\",index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "581effa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "  \n",
    "# # dummy data\n",
    "# x1 = priors['Topics']\n",
    "# A = priors['.01']\n",
    "# B = priors['.05']\n",
    "# C = priors['.1']\n",
    "# D = priors['.2']\n",
    "# E = priors['.5']\n",
    "# F = priors['1']\n",
    "\n",
    "# # creates two subplots\n",
    "# # fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (24, 12))\n",
    "\n",
    "# fig, ax = plt.subplots(2, 3, figsize = (24,12))\n",
    "\n",
    "# # Plot without grid\n",
    "# ax[0,0].plot(x1, A, label='0.01', color='tab:blue')\n",
    "# ax[0,1].plot(x1, B, label='0.05', color='tab:orange')\n",
    "# ax[0,2].plot(x1, C, label='0.1', color='tab:green')\n",
    "# ax[1,0].plot(x1, D, label='0.2', color='tab:red')\n",
    "# ax[1,1].plot(x1, E, label='0.5', color='tab:purple')\n",
    "# ax[1,2].plot(x1, F, label='1', color='tab:brown')\n",
    "\n",
    "# ax[0,0].set_xlim(xmin=9)\n",
    "# ax[0,0].set_title('siri, Î±=.01, Beta=1/K')\n",
    "# ax[0,0].set_xlabel('K')\n",
    "# ax[0,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,1].set_xlim(xmin=9)\n",
    "# ax[0,1].set_title('siri, Î±=.05, Beta=1/K')\n",
    "# ax[0,1].set_xlabel('K')\n",
    "# ax[0,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,2].set_xlim(xmin=9)\n",
    "# ax[0,2].set_title('siri, Î±=.1, Beta=1/K')\n",
    "# ax[0,2].set_xlabel('K')\n",
    "# ax[0,2].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,0].set_xlim(xmin=9)\n",
    "# ax[1,0].set_title('siri, Î±=.2, Beta=1/K')\n",
    "# ax[1,0].set_xlabel('K')\n",
    "# ax[1,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,1].set_xlim(xmin=9)\n",
    "# ax[1,1].set_title('siri, Î±=.5, Beta=1/K')\n",
    "# ax[1,1].set_xlabel('K')\n",
    "# ax[1,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,2].set_xlim(xmin=9)\n",
    "# ax[1,2].set_title('siri, Î±=1, Beta=1/K')\n",
    "# ax[1,2].set_xlabel('K')\n",
    "# ax[1,2].set_ylabel('Cv')\n",
    "\n",
    "# # fig.tight_layout()\n",
    "# fig.set_facecolor(\"w\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
